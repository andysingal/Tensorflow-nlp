{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#It can be seen that the  entity, which is calculated by measuring the frequency of two words appearing close to each other, behaves in different ways as the relationship between the three words changes. As a result, it becomes a good candidate for learning word vectors. \n"
      ],
      "metadata": {
        "id": "tzAQ-n1cFT4M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classifying documents with embeddings"
      ],
      "metadata": {
        "id": "C7tfPdTcF2Ug"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qbWc1UybFTAj"
      },
      "outputs": [],
      "source": [
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "%matplotlib inline\n",
        "from six.moves.urllib.request import urlretrieve\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from matplotlib import pylab\n",
        "from scipy.sparse import lil_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading the data\n",
        "This code downloads a BBC dataset consisting of news articles published by BBC."
      ],
      "metadata": {
        "id": "7vOB-XDKGUHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
        "\n",
        "\n",
        "def download_data(url, data_dir):\n",
        "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "    \n",
        "    # Create the data directory if not exist\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
        "    \n",
        "    # If file doesnt exist, download\n",
        "    if not os.path.exists(file_path):\n",
        "        print('Downloading file...')\n",
        "        filename, _ = urlretrieve(url, file_path)\n",
        "    else:\n",
        "        print(\"File already exists\")\n",
        "  \n",
        "    extract_path = os.path.join(data_dir, 'bbc')\n",
        "    \n",
        "    # If data has not been extracted already, extract data\n",
        "    if not os.path.exists(extract_path):        \n",
        "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
        "            zipf.extractall(data_dir)\n",
        "    else:\n",
        "        print(\"bbc-fulltext.zip has already been extracted\")\n",
        "    \n",
        "download_data(url, 'data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DZxRa0kF72h",
        "outputId": "bea5b389-c4e2-436c-a163-98e437bc50cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists\n",
            "bbc-fulltext.zip has already been extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_dir):\n",
        "    \n",
        "    # This will contain the full list of stories\n",
        "    news_stories = []    \n",
        "    filenames = []\n",
        "    print(\"Reading files\")\n",
        "    \n",
        "    i = 0 # Just used for printing progress\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        \n",
        "        for fi, f in enumerate(files):\n",
        "            \n",
        "            # We don't read the readme file\n",
        "            if 'readme' in f.lower():\n",
        "                continue\n",
        "            \n",
        "            # Printing progress\n",
        "            i += 1\n",
        "            print(\".\"*i, f, end='\\r')\n",
        "            \n",
        "            # Open the file\n",
        "            with open(os.path.join(root, f), encoding='latin-1') as text_file:\n",
        "                \n",
        "                story = []\n",
        "                # Read all the lines\n",
        "                for row in text_file:\n",
        "                                        \n",
        "                    story.append(row.strip())\n",
        "                    \n",
        "                # Create a single string with all the rows in the doc\n",
        "                story = ' '.join(story)                        \n",
        "                # Add that to the list\n",
        "                news_stories.append(story)  \n",
        "                filenames.append(os.path.join(root, f))\n",
        "                \n",
        "        print('', end='\\r')\n",
        "        \n",
        "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
        "    return news_stories, filenames\n",
        "                \n",
        "  \n",
        "news_stories, filenames = read_data(os.path.join('data', 'bbc'))\n",
        "\n",
        "# Printing some stats and sample data\n",
        "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
        "print('Example words (start): ',news_stories[0][:50])\n",
        "print('Example words (end): ',news_stories[-1][-50:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tY1mtYKGZpE",
        "outputId": "b45a1a66-91d6-4398-d4bb-453df72b865f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files\n",
            "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 063.txt\n",
            "Detected 2225 stories\n",
            "865163 words found in the total news set\n",
            "Example words (start):  Kenyon denies Robben Barca return  Chelsea chief e\n",
            "Example words (end):  , along with French singer/actor, Jacques Dutronc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build a Tokenizer\n",
        "Here we build a tokenizer, that performs simple preprocessing like,\n",
        "\n",
        "Converting letters to lower case\n",
        "Removing punctuation\n",
        "and tokenize the strings based on a defined separator. Then each token is converted to an Integer ID, as computers understand numbers, not strings. In the background, the tokenizer builds a word to index dictionary, that defines a unique ID for each word in the vocabulary."
      ],
      "metadata": {
        "id": "8g526pOXGqT0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "n_vocab = 15000 + 1\n",
        "tokenizer = Tokenizer(\n",
        "    num_words=n_vocab - 1,\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "    lower=True, split=' ', oov_token=''\n",
        ")\n",
        "\n",
        "tokenizer.fit_on_texts(news_stories)\n",
        "print(\"Data fitted on the tokenizer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al-oYkiuGefR",
        "outputId": "5ae34f03-9d0e-47ad-c8eb-84c7d7d129e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data fitted on the tokenizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating the word co-occurrence matrix\n",
        "Why GloVe shine above context window based method is that it employs global statistics of the corpus in to the model (according to authors). This is done by using information from the word co-occurance matrix to optimize the word vectors. Basically, the  entry of the co-occurance matrix says how frequent word  to appear near .\n",
        "\n",
        "We also use an optional weighting mechanishm to give more weight to words close together than to the ones further-apart (from experiments section of the paper).\n",
        "\n",
        "Note: When generating the matrix for the first time, it will take a significant amount of time to run\n",
        "\n"
      ],
      "metadata": {
        "id": "EMk_4sDFGzwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import save_npz, load_npz\n",
        "\n",
        "def generate_cooc_matrix(text, tokenizer, window_size, n_vocab, use_weighting=True):\n",
        "    \n",
        "    # Convert list of text to list of list of word IDs\n",
        "    sequences = tokenizer.texts_to_sequences(text)\n",
        "    \n",
        "    # A sparse matrix to retain co-occurrences of words\n",
        "    cooc_mat = lil_matrix((n_vocab, n_vocab), dtype=np.float32)\n",
        "    \n",
        "    # Go through each sequence one by one\n",
        "    for si, sequence in enumerate(sequences):\n",
        "        \n",
        "        # Printing the progress\n",
        "        if (si+1)%100==0:\n",
        "            print('.'*((si+1)//100), f\"{si+1}/{len(sequences)}\", end='\\r')\n",
        "        \n",
        "        # For each target word,\n",
        "        for i, wi in zip(np.arange(window_size, len(sequence)-window_size), sequence[window_size:-window_size]):\n",
        "            \n",
        "            # Get the context window word IDs\n",
        "            context_window = sequence[i-window_size: i+window_size+1]            \n",
        "            \n",
        "            # The weight for the words in the context window (except target word) will be 1\n",
        "            window_weights = np.ones(shape=(window_size*2 + 1,), dtype=np.float32)\n",
        "            window_weights[window_size] = 0.0\n",
        "\n",
        "            if use_weighting:\n",
        "                # If weighting is used, penalize context words based on distance to target word\n",
        "                distances = np.abs(np.arange(-window_size, window_size+1))\n",
        "                distances[window_size] = 1.0\n",
        "                # Update the sparse matrix\n",
        "                cooc_mat[wi, context_window] += window_weights/distances\n",
        "            else:\n",
        "                # Update the sparse matrix\n",
        "                cooc_mat[wi, context_window] += window_weights\n",
        "    \n",
        "    print(\"\\n\")\n",
        "    \n",
        "    return cooc_mat\n",
        "generate_cooc = False\n",
        "\n",
        "\n",
        "# Generate the matrix\n",
        "if generate_cooc:\n",
        "    t1 = time.time()\n",
        "    cooc_mat = generate_cooc_matrix(news_stories, tokenizer, 1, n_vocab, True)\n",
        "    t2 = time.time()\n",
        "    print(f\"It took {t2-t1} seconds to generate the co-occurrence matrix\")\n",
        "    \n",
        "    save_npz(os.path.join('data','cooc_mat.npz'), cooc_mat.tocsr())\n",
        "# Load the matrix from disk\n",
        "else:\n",
        "    try:\n",
        "        cooc_mat = load_npz(os.path.join('data','cooc_mat.npz')).tolil()\n",
        "        print(f\"Cooc matrix of type {type(cooc_mat).__name__} was loaded from disk\")\n",
        "    except FileNotFoundError as ex:\n",
        "        raise FileNotFoundError(\n",
        "            \"Could not find the co-occurrence matrix on the disk. Did you generate the matrix by setting generate_cooc=True?\"\n",
        "        )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IV6plY6ZGuGc",
        "outputId": "833b921f-b6bc-457a-ee45-106201f16a67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cooc matrix of type lil_matrix was loaded from disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "word = 'sport'\n",
        "assert word in tokenizer.word_index, f\"Word {word} is not in the tokenizer\"\n",
        "assert tokenizer.word_index[word] <= n_vocab, f\"The word {word} is an out of vocabuary word. Please try something else\"\n",
        "\n",
        "# Get the vector of co-occurrences for a given word \n",
        "cooc_vec = np.array(cooc_mat.getrow(tokenizer.word_index[word]).todense()).ravel()\n",
        "# Get indices of words with maximum value\n",
        "max_ind = np.argsort(cooc_vec)[-25:]\n",
        "\n",
        "# Plot the words and values\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.bar(np.arange(0, 25), cooc_vec[max_ind])\n",
        "plt.xticks(ticks=np.arange(0, 25), labels=[tokenizer.index_word[i] for i in max_ind], rotation=60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M9xebqQiNki8",
        "outputId": "cc751e12-2d55-40c4-c693-e8af629526ef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7ff91588b820>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91588b7f0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff9196950a0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91580b9a0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91580beb0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91581f400>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91581f910>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91581fe20>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915823370>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915823880>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915823d90>,\n",
              "  <matplotlib.axis.XTick at 0x7ff9158292e0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915823af0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91581fb80>,\n",
              "  <matplotlib.axis.XTick at 0x7ff91580bc10>,\n",
              "  <matplotlib.axis.XTick at 0x7ff9158299a0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915829eb0>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915831400>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915831910>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915831e20>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915836370>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915836880>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915831a30>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915823a60>,\n",
              "  <matplotlib.axis.XTick at 0x7ff915829370>],\n",
              " [Text(0, 0, 'those'),\n",
              "  Text(0, 0, 'complex'),\n",
              "  Text(0, 0, 'about'),\n",
              "  Text(0, 0, 'it'),\n",
              "  Text(0, 0, 'working'),\n",
              "  Text(0, 0, 'only'),\n",
              "  Text(0, 0, 'taxes'),\n",
              "  Text(0, 0, 'were'),\n",
              "  Text(0, 0, 'as'),\n",
              "  Text(0, 0, 'box'),\n",
              "  Text(0, 0, 'or'),\n",
              "  Text(0, 0, 'is'),\n",
              "  Text(0, 0, 'will'),\n",
              "  Text(0, 0, 'more'),\n",
              "  Text(0, 0, 'against'),\n",
              "  Text(0, 0, 'have'),\n",
              "  Text(0, 0, 'are'),\n",
              "  Text(0, 0, ''),\n",
              "  Text(0, 0, 'who'),\n",
              "  Text(0, 0, 'in'),\n",
              "  Text(0, 0, 'to'),\n",
              "  Text(0, 0, 'the'),\n",
              "  Text(0, 0, 'of'),\n",
              "  Text(0, 0, 'for'),\n",
              "  Text(0, 0, 'and')])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GloVe Algorithm\n",
        "Defining Hyperparameters\n",
        "Here we define several hyperparameters including batch_size (amount of samples in a single batch) embedding_size (size of embedding vectors) window_size (context window size).\n"
      ],
      "metadata": {
        "id": "xFsBZeLIHOls"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4096 # Data points in a single batch\n",
        "\n",
        "embedding_size = 128 # Dimension of the embedding vector.\n",
        "\n",
        "window_size=1 # We use a window size of 1 on either side of target word\n",
        "\n",
        "epochs = 5 # Number of epochs to train for\n",
        "\n",
        "# We pick a random validation set to sample nearest neighbors\n",
        "valid_size = 16 # Random set of words to evaluate similarity on.\n",
        "# We sample valid datapoints randomly from a large window without always being deterministic\n",
        "valid_window = 250\n",
        "\n",
        "# When selecting valid examples, we select some of the most frequent words as well as\n",
        "# some moderately rare words as well\n",
        "np.random.seed(54321)\n",
        "random.seed(54321)\n",
        "\n",
        "valid_term_ids = np.array(random.sample(range(valid_window), valid_size))\n",
        "valid_term_ids = np.append(\n",
        "    valid_term_ids, random.sample(range(1000, 1000+valid_window), valid_size),\n",
        "    axis=0\n",
        ")"
      ],
      "metadata": {
        "id": "7sj9U_ZcG5zB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.layers import Input, Embedding, Dot, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Define two input layers for context and target words\n",
        "word_i = Input(shape=())\n",
        "word_j = Input(shape=())\n",
        "\n",
        "# Each context and target has their own embeddings (weights and biases)\n",
        "\n",
        "# Embedding weights\n",
        "embeddings_i = Embedding(n_vocab, embedding_size, name='target_embedding')(word_i)\n",
        "embeddings_j = Embedding(n_vocab, embedding_size, name='context_embedding')(word_j)\n",
        "\n",
        "# Embedding biases\n",
        "b_i = Embedding(n_vocab, 1, name='target_embedding_bias')(word_i)    \n",
        "b_j = Embedding(n_vocab, 1, name='context_embedding_bias')(word_j)\n",
        "\n",
        "# Compute the dot product between embedding vectors (i.e. w_i.w_j)\n",
        "ij_dot = Dot(axes=-1)([embeddings_i,embeddings_j])\n",
        "\n",
        "# Add the biases (i.e. w_i.w_j + b_i + b_j )\n",
        "pred = Add()([ij_dot, b_i, b_j])\n",
        "\n",
        "# The final model\n",
        "glove_model = Model(inputs=[word_i, word_j],outputs=pred, name='glove_model')\n",
        "\n",
        "# Glove has a specific loss function with a sound mathematical underpinning\n",
        "# It is a form of mean squared error\n",
        "glove_model.compile(loss=\"mse\", optimizer = 'adam')\n",
        "\n",
        "glove_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2k8ffFSRHYDb",
        "outputId": "2db57a88-ab5e-4b2f-e1d8-5f307f4a4df5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"glove_model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " target_embedding (Embedding)   (None, 128)          1920128     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " context_embedding (Embedding)  (None, 128)          1920128     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " dot (Dot)                      (None, 1)            0           ['target_embedding[0][0]',       \n",
            "                                                                  'context_embedding[0][0]']      \n",
            "                                                                                                  \n",
            " target_embedding_bias (Embeddi  (None, 1)           15001       ['input_1[0][0]']                \n",
            " ng)                                                                                              \n",
            "                                                                                                  \n",
            " context_embedding_bias (Embedd  (None, 1)           15001       ['input_2[0][0]']                \n",
            " ing)                                                                                             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 1)            0           ['dot[0][0]',                    \n",
            "                                                                  'target_embedding_bias[0][0]',  \n",
            "                                                                  'context_embedding_bias[0][0]'] \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,870,258\n",
            "Trainable params: 3,870,258\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating data for GloVe model\n",
        "The Glove model we implemented,\n",
        "\n",
        "Takes two inputs; context words and target words\n",
        "Computes the mean squared error as, \n",
        " for the model output \n",
        "Use sample weights returned by \n",
        "Therefore, in the data generator we return a tuple of,\n",
        "\n",
        "(inputs, targets, sample weights)\n",
        "\n",
        "which translates to,\n",
        "\n",
        "((batch of target words, batch or context words), batch of log(X_{ij}), batch of f(X_{ij})"
      ],
      "metadata": {
        "id": "4Lk1U--JuiJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_sequences = tokenizer.texts_to_sequences(news_stories)"
      ],
      "metadata": {
        "id": "MXSTjLM6vXkx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def glove_data_generator(\n",
        "    sequences, window_size, batch_size, vocab_size, cooccurrence_matrix, x_max=100.0, alpha=0.75, seed=None\n",
        "):\n",
        "    \"\"\" Generate batches of inputs and targets for GloVe \"\"\"\n",
        "    \n",
        "    # Shuffle the data so that, every epoch, the order of data is different\n",
        "    rand_sequence_ids = np.arange(len(sequences))                    \n",
        "    np.random.shuffle(rand_sequence_ids)\n",
        "\n",
        "    # We will use a sampling table to make sure, we don't oversample stopwords\n",
        "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "    \n",
        "    # For each story/article\n",
        "    for si in rand_sequence_ids:\n",
        "        \n",
        "        # Generate positive skip-grams while using sub-sampling \n",
        "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "            sequences[si], \n",
        "            vocabulary_size=vocab_size, \n",
        "            window_size=window_size, \n",
        "            negative_samples=0.0, \n",
        "            shuffle=False,   \n",
        "            sampling_table=sampling_table,\n",
        "            seed=seed\n",
        "        )\n",
        "        \n",
        "        # Take targets and context words separately\n",
        "        targets, context = zip(*positive_skip_grams)\n",
        "        targets, context = np.array(targets).ravel(), np.array(context).ravel()\n",
        "        \n",
        "        \n",
        "        x_ij = np.array(cooccurrence_matrix[targets, context].toarray()).ravel()\n",
        "        \n",
        "        # Compute log - Introducing an additive shift to make sure we don't compute log(0)\n",
        "        log_x_ij = np.log(x_ij + 1)\n",
        "        \n",
        "        # Sample weights \n",
        "        # if x < x_max => (x/x_max)**alpha / else => 1        \n",
        "        sample_weights = np.where(x_ij < x_max, (x_ij/x_max)**alpha, 1)\n",
        "        \n",
        "        # If seed is not provided generate a random one\n",
        "        if not seed:\n",
        "            seed = random.randint(0, 10e6)\n",
        "        \n",
        "        # Shuffle data\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(context)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(targets)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(log_x_ij)\n",
        "        np.random.seed(seed)\n",
        "        np.random.shuffle(sample_weights)\n",
        "        \n",
        "        # Generate a batch or data in the format \n",
        "        # ((target words, context words), log(X_ij) <- true targets, f(X_ij) <- sample weights)\n",
        "        for eg_id_start in range(0, context.shape[0], batch_size):            \n",
        "            yield (\n",
        "                targets[eg_id_start: min(eg_id_start+batch_size, targets.shape[0])], \n",
        "                context[eg_id_start: min(eg_id_start+batch_size, context.shape[0])]\n",
        "            ), log_x_ij[eg_id_start: min(eg_id_start+batch_size, x_ij.shape[0])], \\\n",
        "            sample_weights[eg_id_start: min(eg_id_start+batch_size, sample_weights.shape[0])]\n",
        "\n",
        "\n",
        "# Generate some data\n",
        "news_glove_data_gen = glove_data_generator(\n",
        "    news_sequences, 2, 10, n_vocab, cooc_mat\n",
        ")\n",
        "\n",
        "for x, y, z in news_glove_data_gen:\n",
        "    print(x)\n",
        "    print(y)\n",
        "    print(z)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bZNa_tYkaWh",
        "outputId": "dc645b6d-13f3-4998-a49c-3a167f6152d1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([7676,  141, 4703, 9199, 9199,  129, 9199, 1016, 7833, 4703]), array([ 146,  769,  769,    2, 1698,   24, 3728,   54,    3,  770]))\n",
            "[0.        0.        0.        0.        0.        2.3025851 0.\n",
            " 0.        0.        0.       ]\n",
            "[0.         0.         0.         0.         0.         0.16431677\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training the model\n",
        "Here we train the GloVe model we defined above. We train for epochs and at the end of each epoch, we compute word similarities on a set of chosen validation words (valid_term_ids). Similar to in Chapter 3, we use a Keras callback to compute the most similar words.\n",
        "\n",
        "Calculating Word Similarities\n",
        "We calculate the similarity between two given words in terms of the cosine distance. To do this efficiently we use matrix operations to do so, as shown below. Furthermore, we define the computations as a callback, which will automatically run at the end of an epoch during model training.\n",
        "\n"
      ],
      "metadata": {
        "id": "YvThlyKGx-QM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidationCallback(tf.keras.callbacks.Callback):\n",
        "    \n",
        "    def __init__(self, valid_term_ids, model_with_embeddings, tokenizer):\n",
        "        \n",
        "        self.valid_term_ids = valid_term_ids\n",
        "        self.model_with_embeddings = model_with_embeddings\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        \"\"\" Validation logic \"\"\"\n",
        "                \n",
        "        # We will use context embeddings to get the most similar words\n",
        "        # Other strategies include: using target embeddings, mean embeddings after avaraging context/target\n",
        "        embedding_weights = self.model_with_embeddings.get_layer(\"context_embedding\").get_weights()[0]\n",
        "        normalized_embeddings = embedding_weights / np.sqrt(np.sum(embedding_weights**2, axis=1, keepdims=True))\n",
        "        \n",
        "        # Get the embeddings corresponding to valid_term_ids\n",
        "        valid_embeddings = normalized_embeddings[self.valid_term_ids, :]\n",
        "        \n",
        "        # Compute the similarity between valid_term_ids and all the embeddings\n",
        "        # V x d (d x D) => V x D\n",
        "        top_k = 5 # Top k items will be displayed\n",
        "        similarity = np.dot(valid_embeddings, normalized_embeddings.T)\n",
        "        \n",
        "        # Invert similarity matrix to negative\n",
        "        # Ignore the first one because that would be the same word as the probe word\n",
        "        similarity_top_k = np.argsort(-similarity, axis=1)[:, 1: top_k+1]\n",
        "                \n",
        "        # Print the output\n",
        "        for i, term_id in enumerate(valid_term_ids):\n",
        "            \n",
        "            similar_word_str = ', '.join([self.tokenizer.index_word[j] for j in similarity_top_k[i, :] if j > 1])\n",
        "            print(f\"{self.tokenizer.index_word[term_id]}: {similar_word_str}\")\n",
        "        \n",
        "        print('\\n')"
      ],
      "metadata": {
        "id": "o_6W6DrpyATX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_validation_callback = ValidationCallback(valid_term_ids, glove_model, tokenizer)\n",
        "\n",
        "# Train the model for several epochs\n",
        "for ei in range(epochs):\n",
        "    \n",
        "    print(f\"Epoch: {ei+1}/{epochs} started\")\n",
        "    \n",
        "    news_glove_data_gen = glove_data_generator(\n",
        "        news_sequences, window_size, batch_size, n_vocab, cooc_mat\n",
        "    )\n",
        "    \n",
        "    glove_model.fit(\n",
        "        news_glove_data_gen, epochs=1, \n",
        "        callbacks=glove_validation_callback,        \n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJhxYs_VyFCk",
        "outputId": "a6526e92-0130-45af-cf2b-0f32b7e9bb8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5 started\n",
            "   2225/Unknown - 100s 45ms/step - loss: 0.3994election: secretary, director, the, time, quarter\n",
            "months: wear, scotland, users, people, pay\n",
            "with: for, from, first, by, new\n",
            "you: they, we, being, going, set\n",
            "were: are, if, where, because, had\n",
            "win: number, out, service, us\n",
            "those: people, technology, now, plans\n",
            "music: content, any, other, all, us\n",
            "also: now, which, it, they, there\n",
            "around: number, down, by, or, other\n",
            "best: award, former, after, uk, industry\n",
            "him: them, all, their, any, his\n",
            "too: so, award, very, after, best\n",
            "into: by, against, set, move, behind\n",
            "through: for, by, from, first, over\n",
            "mr: tony, insisted, james, contract, has\n",
            "example: blogsphere, birkett, parkinson's, construed, embrace\n",
            "concern: match, sunday, them, labour, us\n",
            "trading: episode, madden, finalised, swank, abolishing\n",
            "light: five, how, sent, after, now\n",
            "fast: by, new, or, set\n",
            "north: number, in, from, or, top\n",
            "person: sideways, pelted, maroon, operator, 180bn\n",
            "states: buckingham, cardinal, romanian, o'brien, campaigner\n",
            "giving: she, he, it, asked, able\n",
            "peter: farming, ivo, gael, evident, trainers\n",
            "deutsche: disadvantage, dysfunctional, advertisers, quinn, hayley\n",
            "g: bagle, subscribers, stake, center, firing\n",
            "j: dollars, 2004's, shaking, 2010, trackers\n",
            "favourite: corp's, sincerely, attacking, yantai, 1973\n",
            "stay: order, rise, london, director, gaming\n",
            "fear: like, after, with, first, by\n",
            "\n",
            "\n",
            "2225/2225 [==============================] - 100s 45ms/step - loss: 0.3994\n",
            "Epoch: 2/5 started\n",
            "   2224/Unknown - 91s 41ms/step - loss: 0.0221election: director, labour's, secretary, the, starring\n",
            "months: start, stop, us, technologies, japan\n",
            "with: first, comments, private, from, for\n",
            "you: we, they, even, going, i\n",
            "were: are, because, if, where, can\n",
            "win: them, concerns, part, service, us\n",
            "those: people, once, issues, plans, go\n",
            "music: content, video, them, london, service\n",
            "also: which, given, it, there, make\n",
            "around: south, future, uk, end, new\n",
            "best: foxx, award, free, industry, uk\n",
            "him: them, came, tax, all, president\n",
            "too: so, very, after, running, way\n",
            "into: set, come, behind, us, decision\n",
            "through: full, over, strong, back, off\n",
            "mr: james, tony, iraq, fair, contract\n",
            "example: labour, women, sunday, return, place\n",
            "concern: a, running, 14, book, quality\n",
            "trading: episode, madden, finalised, gamers, abolishing\n",
            "light: technology, proposed, out, sent, five\n",
            "fast: president, sale, festival, economy, record\n",
            "north: chancellor, uk, us, biggest, around\n",
            "person: sideways, pelted, maroon, 180bn, regain\n",
            "states: according, visit, ready, others, wear\n",
            "giving: son, she, justified, able, it\n",
            "peter: france, williams, 2002, david, children\n",
            "deutsche: hard, show, positive, fast, state\n",
            "g: bagle, subscribers, stake, center, firing\n",
            "j: smith, and, former, digital, news\n",
            "favourite: going, ensure, war, expected, likely\n",
            "stay: order, london, director, rise, england\n",
            "fear: way, player, market, right, technology\n",
            "\n",
            "\n",
            "2225/2225 [==============================] - 91s 41ms/step - loss: 0.0221\n",
            "Epoch: 3/5 started\n",
            "   2225/Unknown - 88s 40ms/step - loss: 0.0100election: director, labour's, secretary, the, starring\n",
            "months: pay, immigration, start, both, them\n",
            "with: set, meeting, held, comments, new\n",
            "you: we, they, even, i, asked\n",
            "were: where, are, if, because, tell\n",
            "win: them, oil, concerns, needs, part\n",
            "those: once, people, need, then, issues\n",
            "music: content, video, scotland, france, immigration\n",
            "also: given, which, revealed, nothing, there\n",
            "around: south, future, end, uk, company\n",
            "best: foxx, musical, free, industry, biggest\n",
            "him: them, came, sale, career, sport\n",
            "too: so, shows, idea, way, technology\n",
            "into: come, move, set, questioned, court\n",
            "through: full, off, tory, strong, over\n",
            "mr: tony, james, iraq, hand, production\n",
            "example: place, list, scotland, conservative, labour\n",
            "concern: match, him, them, part, both\n",
            "trading: particular, 2003, 2004, 2005, january\n",
            "light: development, majority, cost, four, support\n",
            "fast: president, economy, sale, biggest, club\n",
            "north: biggest, company, result, future, end\n",
            "person: own, yugansk, committee, efforts, store\n",
            "states: according, ready, continue, announce, visit\n",
            "giving: son, able, white, it's, later\n",
            "peter: williams, kept, children, bush, computers\n",
            "deutsche: speculation, movie, companies, hard, keep\n",
            "g: bagle, stake, center, firing, emerging\n",
            "j: game, digital, organisation, bid, former\n",
            "favourite: left, online, player, meeting, iraq\n",
            "stay: order, london, 2005, sport, december\n",
            "fear: player, right, way, market, five\n",
            "\n",
            "\n",
            "2225/2225 [==============================] - 88s 40ms/step - loss: 0.0100\n",
            "Epoch: 4/5 started\n",
            "   2224/Unknown - 91s 41ms/step - loss: 0.0075election: director, labour's, the, secretary, service\n",
            "months: start, turn, immigration, pay, huge\n",
            "with: held, set, great, meeting, find\n",
            "you: we, they, even, asked, i\n",
            "were: where, are, received, say, if\n",
            "win: available, them, oil, order, needs\n",
            "those: once, researcher, boy, people, need\n",
            "music: content, video, france, scotland, computers\n",
            "also: given, which, 11, looking, revealed\n",
            "around: end, future, uk, news, case\n",
            "best: foxx, video, musical, free, award\n",
            "him: them, pay, order, go, career\n",
            "too: so, idea, way, running, shows\n",
            "into: behind, tories, lost, how, information\n",
            "through: full, tory, strong, bid, signing\n",
            "mr: tony, james, attacks, production, hand\n",
            "example: place, millions, list, november, return\n",
            "concern: period, them, health, fast, pay\n",
            "trading: november, particular, 2005, range, early\n",
            "light: part, 2000, china's, europe, place\n",
            "fast: biggest, part, album, early, president\n",
            "north: job, result, key, issue, ball\n",
            "person: poverty, industry, news, side, wrong\n",
            "states: according, politics, visit, order, authorities\n",
            "giving: forced, looking, asked, start, currently\n",
            "peter: 2002, david, x, popularity, 50\n",
            "deutsche: speculation, takes, companies, hard, iraq\n",
            "g: stake, bagle, center, firing, emerging\n",
            "j: following, south, decision, game, news\n",
            "favourite: meeting, online, iraq, following, left\n",
            "stay: london, least, friday, course, ahead\n",
            "fear: right, football, promised, allowed, let\n",
            "\n",
            "\n",
            "2225/2225 [==============================] - 91s 41ms/step - loss: 0.0075\n",
            "Epoch: 5/5 started\n",
            "   2224/Unknown - 88s 40ms/step - loss: 0.0060election: labour's, director, the, service, computers\n",
            "months: plan, ireland, came, fight, poverty\n",
            "with: held, set, picked, find, comments\n",
            "you: they, we, even, critical, asked\n",
            "were: where, received, are, say, because\n",
            "win: oil, order, them, needs, went\n",
            "those: researcher, boy, leader, need, people\n",
            "music: content, video, france, include, computers\n",
            "also: given, which, start, revealed, agreed\n",
            "around: end, future, uk, case, news\n",
            "best: foxx, award, free, video, musical\n",
            "him: me, using, battle, order, came\n",
            "too: so, way, idea, shows, attempt\n",
            "into: points, seen, money, plan, behind\n",
            "through: bid, tory, signing, to, poor\n",
            "mr: tony, james, wednesday's, production, attacks\n",
            "example: labour, marriages, conservative, award, training\n",
            "concern: concerns, health, china's, worried, travel\n",
            "trading: november, north, 2003, january, particular\n",
            "light: university, thousands, china's, 2000, majority\n",
            "fast: album, me, biggest, least, range\n",
            "north: president, job, biggest, winning, ball\n",
            "person: final, came, dollar, wrong, late\n",
            "states: order, visit, evidence, grow, nature\n",
            "giving: 20, looking, forced, currently, plan\n",
            "peter: 2002, david, x, popularity, 50\n",
            "deutsche: plan, iraq, takes, companies, poverty\n",
            "g: bagle, biogen, center, firing, emerging\n",
            "j: bid, launch, following, news, standard\n",
            "favourite: online, meeting, leader, iraq, plan\n",
            "stay: london, least, ahead, friday, favour\n",
            "fear: football, promised, italian, drugs, project\n",
            "\n",
            "\n",
            "2225/2225 [==============================] - 88s 40ms/step - loss: 0.0060\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the embeddings\n",
        "We save the learned embeddings to the disk"
      ],
      "metadata": {
        "id": "BN_BSCt3ymLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_embeddings(model, tokenizer, vocab_size, save_dir):\n",
        "    \n",
        "    # Create the directory if doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    \n",
        "    # Get the words sorted according to their ID from the tokenizer\n",
        "    _, words_sorted = zip(*sorted(list(tokenizer.index_word.items()), key=lambda x: x[0])[:vocab_size-1])\n",
        "    # Add one word in front to represent the reserved ID (0)\n",
        "    words_sorted = [None] + list(words_sorted)\n",
        "    \n",
        "    # Create a new array by concatenating embeddings and bias\n",
        "    \n",
        "    context_embedding_weights = model.get_layer(\"context_embedding\").get_weights()[0]\n",
        "    context_embedding_bias = model.get_layer(\"context_embedding_bias\").get_weights()[0]\n",
        "    context_embedding = np.concatenate([context_embedding_weights, context_embedding_bias], axis=1)\n",
        "    \n",
        "    target_embedding_weights = model.get_layer(\"target_embedding\").get_weights()[0]\n",
        "    target_embedding_bias = model.get_layer(\"target_embedding_bias\").get_weights()[0]\n",
        "    target_embedding = np.concatenate([target_embedding_weights, target_embedding_bias], axis=1)\n",
        "    \n",
        "    # Save the array as a Pandas DataFrames\n",
        "    pd.DataFrame(\n",
        "        context_embedding, \n",
        "        index = words_sorted\n",
        "    ).to_pickle(os.path.join(save_dir, \"context_embedding_and_bias.pkl\"))\n",
        "    \n",
        "    pd.DataFrame(\n",
        "        target_embedding, \n",
        "        index = words_sorted\n",
        "    ).to_pickle(os.path.join(save_dir, \"target_embedding_and_bias.pkl\"))\n",
        "\n",
        "    \n",
        "save_embeddings(glove_model, tokenizer, n_vocab, save_dir='glove_embeddings')"
      ],
      "metadata": {
        "id": "Ro1qlNjoyJBk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ELMo  Taking ambiguities out of word vectors\n",
        "\n",
        "Therefore, it is more sensible to provide embeddings for a word while preserving and leveraging the context around it. This is exactly what ELMo is striving for.\n",
        "\n",
        " ELMo takes in a sequence, as opposed to a single token, and provides contextualized representations for each token in the sequence. \n",
        " "
      ],
      "metadata": {
        "id": "wn5xQV9_zMgt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are all the modules we'll be using later. Make sure you can import them\n",
        "# before proceeding further.\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "%env TF_FORCE_GPU_ALLOW_GROWTH=true\n",
        "# Making sure we cache the models and are not downloaded all the time\n",
        "%env TFHUB_CACHE_DIR=./tfhub_modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8gU-eD-zRcW",
        "outputId": "1510d37e-49cd-45fa-d839-b85a45f4bf5f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n",
            "env: TFHUB_CACHE_DIR=./tfhub_modules\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using pre-trained ELMo Model\n",
        "Downloading the ELMo Model from TFHub\n",
        "\n",
        "Note that we are providing two arguments, signature and signature_outputs_as_dict:\n",
        "\n",
        "signature (str)  Can be default or tokens. The default signature accepts a list of strings, where each string will be converted to a list of tokens internally. The tokens signature takes in inputs as dictionary having two keys. \n",
        "Namely, tokens (a list of list of tokens. Each list of tokens is a single phrase/sentence and includes padding tokens to bring them to a fixed length) and sequence_len\" (the length of each list of tokens, to determine the padding length).\n",
        "signature_outputs_as_dict (bool)  When set to true, it will return all the outputs defined in the provided signature."
      ],
      "metadata": {
        "id": "JBbAVlA01_c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Remove any ongoing sessions\n",
        "K.clear_session()\n",
        "\n",
        "# Download the ELMo model and save to disk\n",
        "elmo_layer = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\", signature=\"tokens\",signature_outputs_as_dict=True)\n"
      ],
      "metadata": {
        "id": "MEsqh1JG17RG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Formatting the input for ELMo\n",
        "ELMo expects the inputs to be in a specific format. Here we write a function to get the input in that format."
      ],
      "metadata": {
        "id": "LXb6UbHO3r6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_text_for_elmo(texts, lower=True, split=\" \", max_len=None):\n",
        "    \n",
        "    \"\"\" Formats a given text for the ELMo model (takes in a list of strings) \"\"\"\n",
        "        \n",
        "    token_inputs = [] # Maintains individual tokens\n",
        "    token_lengths = [] # Maintains the length of each sequence\n",
        "    \n",
        "    max_len_inferred = 0 # We keep a variable to matain the max length of the input\n",
        "    \n",
        "    # Go through each text (string)\n",
        "    for text in texts:    \n",
        "        \n",
        "        # Process the text and get a list of tokens\n",
        "        tokens = tf.keras.preprocessing.text.text_to_word_sequence(text, lower=lower, split=split)\n",
        "        \n",
        "        # Add the tokens \n",
        "        token_inputs.append(tokens)                   \n",
        "        \n",
        "        # Compute the max length for the collection of sequences\n",
        "        if len(tokens)>max_len_inferred:\n",
        "            max_len_inferred = len(tokens)\n",
        "    \n",
        "    # It's important to make sure the maximum token length is only as large as the longest input in the sequence\n",
        "    # You can't have arbitrarily large length as the maximum length. Otherwise, you'll get this error.\n",
        "    #InvalidArgumentError:  Incompatible shapes: [2,6,1] vs. [2,10,1024]\n",
        "    #    [[node mul (defined at .../python3.6/site-packages/tensorflow_hub/module_v2.py:106) ]] [Op:__inference_pruned_3391]\n",
        "    \n",
        "    # Here we make sure max_len is only as large as the longest input\n",
        "    if max_len and max_len_inferred < max_len:\n",
        "        max_len = max_len_inferred\n",
        "    if not max_len:\n",
        "        max_len = max_len_inferred\n",
        "    \n",
        "    # Go through each token sequence and modify sequences to have same length\n",
        "    for i, token_seq in enumerate(token_inputs):\n",
        "        \n",
        "        token_lengths.append(min(len(token_seq), max_len))\n",
        "        \n",
        "        # If the maximum length is less than input length, truncate\n",
        "        if max_len < len(token_seq):\n",
        "            token_seq = token_seq[:max_len]            \n",
        "        # If the maximum length is greater than or equal to input length, add padding as needed\n",
        "        else:            \n",
        "            token_seq = token_seq+[\"\"]*(max_len-len(token_seq))\n",
        "                \n",
        "        assert len(token_seq)==max_len\n",
        "        \n",
        "        token_inputs[i] = token_seq\n",
        "    \n",
        "    # Return the final output\n",
        "    return {\n",
        "        \"tokens\": tf.constant(token_inputs), \n",
        "        \"sequence_len\": tf.constant(token_lengths)\n",
        "    }\n",
        "\n",
        "\n",
        "print(format_text_for_elmo([\"the cat sat on the mat\", \"the mat sat\"], max_len=10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4mHMhpB2FU7",
        "outputId": "70ac32a1-7781-45f5-8e74-8be7f46882df"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': <tf.Tensor: shape=(2, 6), dtype=string, numpy=\n",
            "array([[b'the', b'cat', b'sat', b'on', b'the', b'mat'],\n",
            "       [b'the', b'mat', b'sat', b'', b'', b'']], dtype=object)>, 'sequence_len': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([6, 3], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Titles of 001.txt - 005.txt in bbc/business\n",
        "elmo_inputs = format_text_for_elmo([\n",
        "    \"Ad sales boost Time Warner profit\",\n",
        "    \"Dollar gains on Greenspan speech\",\n",
        "    \"Yukos unit buyer faces loan claim\",\n",
        "    \"High fuel prices hit BA's profits\",\n",
        "    \"Pernod takeover talk lifts Domecq\"\n",
        "])\n",
        "\n",
        "# Get the result from ELMo\n",
        "elmo_result = elmo_layer(elmo_inputs)\n",
        "\n",
        "# Print the result\n",
        "for k,v in elmo_result.items():    \n",
        "    print(f\"Tensor under key={k} is a {v.shape} shaped Tensor\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs1x9ufr3v8y",
        "outputId": "97c7e558-28d2-4c8b-f1cc-4d3b1ddebac0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor under key=word_emb is a (5, 6, 512) shaped Tensor\n",
            "Tensor under key=default is a (5, 1024) shaped Tensor\n",
            "Tensor under key=elmo is a (5, 6, 1024) shaped Tensor\n",
            "Tensor under key=lstm_outputs2 is a (5, 6, 1024) shaped Tensor\n",
            "Tensor under key=lstm_outputs1 is a (5, 6, 1024) shaped Tensor\n",
            "Tensor under key=sequence_len is a (5,) shaped Tensor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip'\n",
        "\n",
        "\n",
        "def download_data(url, data_dir):\n",
        "    \"\"\"Download a file if not present, and make sure it's the right size.\"\"\"\n",
        "    \n",
        "    # Create the data directory if not exist\n",
        "    os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "    file_path = os.path.join(data_dir, 'bbc-fulltext.zip')\n",
        "    \n",
        "    # If file doesnt exist, download\n",
        "    if not os.path.exists(file_path):\n",
        "        print('Downloading file...')\n",
        "        filename, _ = urlretrieve(url, file_path)\n",
        "    else:\n",
        "        print(\"File already exists\")\n",
        "  \n",
        "    extract_path = os.path.join(data_dir, 'bbc')\n",
        "    \n",
        "    # If data has not been extracted already, extract data\n",
        "    if not os.path.exists(extract_path):        \n",
        "        with zipfile.ZipFile(os.path.join(data_dir, 'bbc-fulltext.zip'), 'r') as zipf:\n",
        "            zipf.extractall(data_dir)\n",
        "    else:\n",
        "        print(\"bbc-fulltext.zip has already been extracted\")\n",
        "    \n",
        "download_data(url, 'data')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chU2Xp_fKzNf",
        "outputId": "0c4c9b65-d668-4f8e-d69d-1be2cfdf126f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File already exists\n",
            "bbc-fulltext.zip has already been extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(data_dir):\n",
        "    \n",
        "    # This will contain the full list of stories\n",
        "    news_stories = []    \n",
        "    filenames = []\n",
        "    print(\"Reading files\")\n",
        "    \n",
        "    i = 0 # Just used for printing progress\n",
        "    for root, dirs, files in os.walk(data_dir):\n",
        "        \n",
        "        for fi, f in enumerate(files):\n",
        "            \n",
        "            # We don't read the readme file\n",
        "            if 'README' in f:\n",
        "                continue\n",
        "            \n",
        "            # Printing progress\n",
        "            i += 1\n",
        "            print(\".\"*i, f, end='\\r')\n",
        "            \n",
        "            # Open the file\n",
        "            with open(os.path.join(root, f), encoding='latin-1') as text_file:\n",
        "                \n",
        "                story = []\n",
        "                # Read all the lines\n",
        "                for row in text_file:\n",
        "                                        \n",
        "                    story.append(row.strip())\n",
        "                    \n",
        "                # Create a single string with all the rows in the doc\n",
        "                story = ' '.join(story)                        \n",
        "                # Add that to the list\n",
        "                news_stories.append(story)  \n",
        "                filenames.append(os.path.join(root, f))\n",
        "                \n",
        "        print('', end='\\r')\n",
        "        \n",
        "    print(f\"\\nDetected {len(news_stories)} stories\")\n",
        "    return news_stories, filenames\n",
        "                \n",
        "  \n",
        "news_stories, filenames = read_data(os.path.join('data', 'bbc'))\n",
        "\n",
        "# Printing some stats and sample data\n",
        "print(f\"{sum([len(story.split(' ')) for story in news_stories])} words found in the total news set\")\n",
        "print('Example words (start): ',news_stories[0][:50])\n",
        "print('Example words (end): ',news_stories[-1][-50:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztmvl3JVP9wp",
        "outputId": "f1a9b07f-3026-4bf6-b6a6-7f97b42ca54c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading files\n",
            "................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................. 063.txt\n",
            "Detected 2225 stories\n",
            "865163 words found in the total news set\n",
            "Example words (start):  Kenyon denies Robben Barca return  Chelsea chief e\n",
            "Example words (end):  , along with French singer/actor, Jacques Dutronc.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.Series([len(x.split(' ')) for x in news_stories]).describe(percentiles=[0.05, 0.95])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNclNvw0QBBm",
        "outputId": "745b011d-1847-485a-8cab-82eeae6400e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    2225.000000\n",
              "mean      388.837303\n",
              "std       241.484273\n",
              "min        91.000000\n",
              "5%        164.200000\n",
              "50%       336.000000\n",
              "95%       736.800000\n",
              "max      4489.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Compute the document embeddings\n",
        "ELMo provides several outputs as the output (in the form of a dictionary). The most important output is in a key called default which is the averaged vector resulting from vectors produced for all the tokens in the input. We will use this as the document embedding.\n",
        "\n"
      ],
      "metadata": {
        "id": "GVttUgOjQMyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "\n",
        "news_elmo_embeddings = []\n",
        "\n",
        "# Go through batches\n",
        "for i in range(0, len(news_stories), batch_size):\n",
        "    \n",
        "    # Print progress\n",
        "    print('.', end='')\n",
        "    # Format ELMo inputs\n",
        "    elmo_inputs = format_text_for_elmo(news_stories[i: min(i+batch_size, len(news_stories))], max_len=768)    \n",
        "    # Get the result stored in default\n",
        "    elmo_result = elmo_layer(elmo_inputs)[\"default\"]\n",
        "    # Add that to a list\n",
        "    news_elmo_embeddings.append(elmo_result)\n",
        "\n",
        "# Create an array\n",
        "news_elmo_embeddings = np.concatenate(news_elmo_embeddings, axis=0)    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXGnLKj4QGyY",
        "outputId": "8af9ca3b-8dae-48fe-cc43-f2b422aa1fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "............................................................................................................................................................................................................................................................................................................................................................................................................."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the data to disk\n",
        "os.makedirs('elmo_embeddings', exist_ok=True)\n",
        "\n",
        "pd.DataFrame(\n",
        "    news_elmo_embeddings, index=filenames\n",
        ").to_pickle(\n",
        "    os.path.join('elmo_embeddings', 'elmo_embeddings.pkl')\n",
        ")\n"
      ],
      "metadata": {
        "id": "3rF5JlgfQQGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "pd.read_pickle(os.path.join('elmo_embeddings', 'elmo_embeddings.pkl'))"
      ],
      "metadata": {
        "id": "kIrbYvk4QXBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}